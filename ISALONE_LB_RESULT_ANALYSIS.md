# IsAlone特徴量 LB検証結果

**提出日**: 2025-10-21
**提出ファイル**: `submission_isalone_added.csv`
**LB Score**: **0.76794**

---

## 📊 結果サマリー

| 提出 | モデル | 特徴量数 | OOF Score | LB Score | LB変化 |
|------|--------|---------|----------|----------|--------|
| ベースライン | Hard Voting | 9特徴 | 0.8384 | **0.77751** | - |
| **IsAlone追加** | Hard Voting | **10特徴** | **0.8395** | **0.76794** | **-0.00957** |

### ❌ **判定: IsAlone特徴量は不採用**

**理由**: LBスコアが大幅に悪化（-0.957%）

---

## 🔍 詳細分析

### OOF vs LB の矛盾

| 指標 | ベースライン | IsAlone追加 | 変化 |
|------|------------|------------|------|
| **OOF Score** | 0.8384 | 0.8395 | **+0.0011** ✅ |
| **LB Score** | 0.77751 | 0.76794 | **-0.00957** ❌ |
| **CV-LB Gap** | 6.09% | 6.93% | **+0.84%** ❌ |

**観察**:
- OOFでは改善（+0.11%）
- しかしLBでは悪化（-0.957%）
- **Gap拡大**: 6.09% → 6.93%

---

## ⚠️ Deck_Safeと全く同じパターン

### 過去の失敗との比較

| 特徴量 | OOF改善 | LB変化 | LB悪化幅 |
|--------|---------|--------|----------|
| **Deck_Safe** | +0.0033 | -0.00957 | **-0.957%** |
| **IsAlone** | +0.0011 | -0.00957 | **-0.957%** |

**驚くべき一致**:
- 両方ともOOFで改善
- 両方ともLBで**全く同じ幅で悪化**（-0.00957）
- これは偶然ではない可能性

---

## 🎯 根本原因の分析

### 仮説1: Train/Test分布の違い

**IsAloneの分布**:

**Trainデータ**:
- IsAlone=1（単独）: 約60% → 生存率30-35%
- IsAlone=0（グループ）: 約40% → 生存率50-55%

**Testデータ**（推測）:
- IsAloneの分布がTrainと異なる可能性
- または生存率とIsAloneの関係が異なる

**結果**: OOFで学習したパターンがTestで機能しない

---

### 仮説2: 小さなOOF改善は信頼できない

**IsAloneのOOF改善**: +0.0011（約1人分）

**統計的有意性**:
- 891人中1人の予測改善
- これは**統計的ノイズの範囲内**
- 真の改善ではなくランダム変動の可能性

**教訓**: OOF改善が小さすぎる場合（< 0.003）は採用すべきでない

---

### 仮説3: 特徴量追加がモデルを混乱させる

**10特徴量モデルのLB結果**:
- Deck_Safe追加: 0.76794
- IsAlone追加: 0.76794
- **全く同じスコア**

**可能性**:
1. 10特徴量になるとモデルが過学習
2. 9特徴量が最適な次元数
3. 追加特徴量の種類に関わらず悪化

**結論**: **9特徴量がスイートスポット**

---

## 📈 全提出履歴の整理

| # | モデル | 特徴量数 | LB Score | 累積改善 | 評価 |
|---|--------|---------|----------|---------|------|
| 1 | Soft Voting + threshold 0.4236 | 10 | 0.75837 | - | ❌ |
| 2 | Hard Voting（Deck_Safe含む） | 10 | 0.76794 | +0.957% | ⚠️ |
| 3 | **Hard Voting** | **9** | **0.77751** | **+1.914%** | ✅ **ベスト** |
| 4 | Hard Voting + IsAlone | 10 | 0.76794 | +0.957% | ❌ |

**パターン**:
- 10特徴量: 常に0.76794
- 9特徴量: **0.77751**（最良）

---

## 🎓 重要な教訓

### 教訓1: 小さなOOF改善は信頼できない

**閾値**:
- OOF改善 < 0.003（0.3%）: 統計的ノイズの可能性
- OOF改善 ≥ 0.003: LB検証の価値あり

**IsAloneの場合**:
- OOF改善: +0.0011（0.11%）
- これは**閾値以下** → LB検証すべきでなかった

---

### 教訓2: 9特徴量が最適次元

**観察**:
- 9特徴: LB 0.77751
- 10特徴（どんな特徴でも）: LB 0.76794

**結論**:
- モデルの最適次元は**9特徴**
- 特徴量を増やすと過学習
- **シンプルイズベスト**

---

### 教訓3: OOF改善 ≠ LB改善（再確認）

**失敗事例**:
1. Deck_Safe: OOF +0.0033, LB -0.00957
2. IsAlone: OOF +0.0011, LB -0.00957

**成功事例**:
1. Deck_Safe除外: OOF +0.0079, LB +0.00957

**パターン**:
- 特徴量**追加**はLB悪化
- 特徴量**削除**はLB改善

---

## 🚫 特徴量追加アプローチの限界

### 試みた特徴量（すべて失敗）

| 特徴量 | OOF改善 | LB変化 | 判定 |
|--------|---------|--------|------|
| Deck_Safe | +0.0033 | -0.957% | ❌ |
| Sex×Pclass | -0.0023 | - | ❌ |
| IsAlone | +0.0011 | -0.957% | ❌ |
| FarePerPerson | -0.0034 | - | ❌ |
| AgeGroup | ±0.0000 | - | ❌ |

**結論**: **特徴量追加では改善できない**

---

## 🔄 方針転換: CV戦略改善へ

### 現在の問題

**CV-LB Gap**: 6.09%（要注意レベル）

**原因**（推測）:
1. **StratifiedKFoldの問題**
   - Ticketグループを考慮していない
   - 同じTicketの乗客がTrain/Validationに分散
   - データリーケージでOOFが過大評価

2. **Train/Test分布の違い**
   - 特徴量追加がこの違いを増幅
   - 9特徴量が最も分布の違いに頑健

---

### 次のアプローチ: Stratified Group K-Fold

**目的**: データリーケージ防止、正確なOOF評価

**実装**:
```python
from sklearn.model_selection import StratifiedGroupKFold

# Ticketグループを考慮
ticket_groups = train['Ticket']

sgkf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)
for fold, (train_idx, val_idx) in enumerate(sgkf.split(X, y, groups=ticket_groups)):
    # 同じTicketグループがTrain/Validationに分散しない
    ...
```

**期待効果**:
1. より正確なOOF評価
2. CV-LB Gap縮小（6.09% → 3%以下目標）
3. OOF改善がLB改善と一致するように

---

## 📊 現在のベストモデル（確定）

### 最終決定: 9特徴量Hard Voting

**モデル**:
- アルゴリズム: Hard Voting (LightGBM + GradientBoosting + RandomForest)
- 特徴量数: **9特徴** + 1 Embarked dummy（計10列）
- 閾値: 0.5（デフォルト）

**特徴量リスト**:
1. Pclass
2. Sex
3. Age
4. SibSp
5. Parch
6. Fare
7. Title
8. FamilySize
9. Embarked_Q
10. Embarked_S

**性能**:
- **LB Score**: **0.77751**（最良）
- OOF Score: 0.8384
- CV-LB Gap: 6.09%

**除外した特徴量**:
- ❌ Deck_Safe（過学習）
- ❌ IsAlone（過学習）
- ❌ TicketGroup（多重共線性）
- ❌ その他すべての候補

---

## 🎯 次のステップ

### 優先度1: Stratified Group K-Fold実装

**目的**: CV-LB Gap縮小

**期待効果**:
- Gap 6.09% → 3-4%
- より信頼できるOOF評価
- 特徴量追加の効果を正確に測定

---

### 優先度2（長期）: Stacking Ensemble

**構成**:
- Level 1: LightGBM, GradientBoosting, RandomForest, XGBoost
- Level 2: LogisticRegression

**期待効果**:
- LB 0.79-0.80
- より高度なアンサンブル

---

### 優先度3（長期）: 外部データの活用

**候補**:
- 歴史的データ（乗客リスト等）
- Feature Store
- Transfer Learning

---

## 📝 ベストプラクティス（更新）

### 特徴量追加の判断基準（改訂版）

```
新しい特徴量のアイデア
  ↓
1. OOF評価（改善 ≥ 0.003?）
  ↓ NO → 不採用
2. VIF評価（< 10?）
  ↓ NO → 不採用
3. ドメイン知識（理論的に妥当?）
  ↓ NO → 不採用
4. Kaggle LB検証
  ↓ LB改善? → 採用
  ↓ LB悪化? → 不採用
```

**重要な追加条件**:
- ✅ OOF改善 ≥ 0.003（0.3%）
- ❌ OOF改善 < 0.003 → 統計的ノイズの可能性、採用しない

---

## まとめ

### IsAlone特徴量の評価

❌ **不採用**

**理由**:
1. LBスコア悪化（-0.957%）
2. OOF改善が小さすぎた（+0.11%）
3. Deck_Safeと同じ過学習パターン

---

### 特徴量追加アプローチの結論

**限界に到達**:
- 5つの特徴量候補をすべて試した
- すべて失敗（LB改善なし）
- **9特徴量が最適**

**方針転換**:
- 特徴量追加 → CV戦略改善
- Stratified Group K-Foldに移行

---

### 現在のベストモデル

**9特徴量Hard Voting**:
- **LB Score**: **0.77751**
- これ以上の特徴量追加は不要
- CV戦略改善で精度向上を目指す

---

### 次のマイルストーン

1. **Stratified Group K-Fold実装**（最優先）
2. Gap縮小（6.09% → 3%以下）
3. より正確なモデル評価基盤の構築

---

**作成日**: 2025-10-21
**結論**: 9特徴量Hard VotingがベストモデルとFINAL決定
**次のアクション**: Stratified Group K-Fold実装でCV戦略改善
