# Age × Pclass 交互作用の評価実験

**日付**: 2025-10-24
**目的**: ブースティング決定木系以外のモデルで、Age × Pclass 交互作用が効果的か検証

## 仮説

ブースティング決定木系（LightGBM, GradientBoosting）は自動的に交互作用を学習できるが、
それ以外のモデル（ロジスティック回帰、SVM等）では明示的に交互作用項を追加することで
精度が改善する可能性がある。

**理論的根拠**:
- 子供（Age < 18）× 1等客: 生存率 ~100%
- 子供（Age < 18）× 3等客: 生存率 ~30-40%
- 高齢者 × 客室クラスでも差異がある
- Age × Pclass の組み合わせは強いシグナルのはず

## 実験内容

### データ
- 使用データ: train.csv (891行)
- 正しい補完パイプライン使用（Train/Test分離を維持）
- ベース特徴量: 12個（Pclass, Sex, Age, SibSp, Parch, Fare, Title, FamilySize, SmallFamily, Embarked関連）

### 交互作用特徴量
Age × Pclass の交互作用を以下のように実装：

```python
# 連続値 × カテゴリの交互作用
Age_Pclass_1 = Age × (Pclass == 1)
Age_Pclass_2 = Age × (Pclass == 2)
Age_Pclass_3 = Age × (Pclass == 3)
```

- ベースライン: 12特徴量
- 交互作用あり: 15特徴量（+3）

### テストモデル

**ブースティング以外のモデル**:
1. **ロジスティック回帰** (LogisticRegression)
   - 線形モデル → 明示的な交互作用項が必要
   - StandardScaler使用

2. **RandomForest**
   - 決定木系だがブースティングではない
   - 深い木（max_depth=5）で連続値を活用

3. **SVM (RBF kernel)**
   - 非線形カーネル
   - StandardScaler使用

### 評価方法
- クロスバリデーション: 5-Fold Stratified K-Fold
- 評価指標: Accuracy (OOF Score)
- 乱数シード: 42

## 結果

### 全体サマリー

| モデル | ベース OOF | 交互作用 OOF | 改善 | 判定 |
|--------|------------|--------------|------|------|
| LogisticRegression | 0.8204 | 0.8193 | **-0.0011** | ❌ 悪化 |
| RandomForest | 0.8305 | 0.8238 | **-0.0067** | ❌ 悪化 |
| SVM_RBF | **0.8316** | 0.8272 | **-0.0045** | ❌ 悪化 |

### 詳細結果

#### ロジスティック回帰
- **ベースライン**: OOF 0.8204, CV 0.8204 ± 0.0121
- **交互作用あり**: OOF 0.8193, CV 0.8193 ± 0.0088
- **改善**: -0.0011（わずかに悪化）
- **結論**: 線形モデルでも交互作用は効果なし

#### RandomForest
- **ベースライン**: OOF 0.8305, CV 0.8305 ± 0.0064
- **交互作用あり**: OOF 0.8238, CV 0.8238 ± 0.0071
- **改善**: -0.0067（明確に悪化）
- **結論**: 決定木は自動的に交互作用を学習するため、明示的な追加は不要

#### SVM (RBF)
- **ベースライン**: OOF **0.8316**, CV 0.8316 ± 0.0138 ⭐
- **交互作用あり**: OOF 0.8272, CV 0.8272 ± 0.0044
- **改善**: -0.0045（悪化）
- **結論**: 非線形カーネルが既に複雑な関係を捉えている

### 意外な発見

**SVM_RBF（ベースライン）が OOF 0.8316 を達成** ← 過去最高級のスコア！

比較:
- 4th提出 Soft Voting: OOF 0.8249, LB 0.78468
- 3rd提出 Hard Voting: OOF 0.8294, LB 0.77751
- **SVM_RBF（新）: OOF 0.8316, LB ?**

⚠️ ただし、**OOFが高い ≠ LBが高い** という重要な教訓あり
- Hard Voting: OOF 0.8294 → LB 0.77751
- Soft Voting: OOF 0.8249 → LB 0.78468（**より低いOOFで高いLB**）

## 考察

### うまくいかなかった点

1. **Age × Pclass 交互作用は全モデルで悪化**
   - 仮説は間違っていた
   - 理論的根拠があっても、実データでは効果なし

2. **多重共線性の問題**
   - Age_Pclass_1 + Age_Pclass_2 + Age_Pclass_3 ≈ Age
   - 情報的に冗長で、モデルを複雑化するだけ

3. **既存特徴量の十分性**
   - ベース12特徴量が既に十分な情報を持っている
   - Title, Pclass, Age が個別に存在すれば十分

### 学んだこと

1. **理論的根拠 ≠ 実験結果**
   - 「子供×1等客」の理論は正しくても、モデルには不要
   - 既存の特徴量（Age, Pclass, Title）で十分表現されている

2. **モデルの自動学習能力**
   - RandomForestは明示的な交互作用なしで関係を学習
   - SVMの非線形カーネルも同様

3. **過去の失敗パターンとの一致**
   - Sex × Pclass: -0.0023（失敗）
   - Age × Pclass: -0.0011 ~ -0.0067（失敗）
   - **交互作用特徴量は一貫して失敗している**

4. **SVM_RBFの可能性**
   - OOF 0.8316は高いが、LBスコアは不明
   - 過去の教訓から、LBで検証する価値はあるが慎重に

## 結論

### ❌ Age × Pclass 交互作用は不採用

**理由**:
1. 全モデルで精度が悪化（-0.0011 ~ -0.0067）
2. 多重共線性の懸念
3. ベース特徴量で十分

### ✅ 新たな発見: SVM_RBF（ベースライン）

**OOF 0.8316** は過去最高級だが、以下の理由で慎重に評価：
1. OOFが高くてもLBが低い前例あり
2. SVM単体 vs アンサンブル（理論的にアンサンブルが優位）
3. 未検証のモデル（リスク不明）

### 推奨アクション

**5th提出戦略への影響**:
- Age × Pclass 交互作用: **使用しない**（失敗実証済み）
- SVM_RBF: **検討の余地あり**（OOF 0.8316）だが、リスク中～高
- **推奨は変わらず**: 4th提出ファイルの再提出（確実性重視）

**次のステップ**:
1. SVM_RBFの提出ファイルを生成（検討用）
2. 5th提出は4th再提出を推奨（改悪リスク回避）
3. SVM_RBFは参考データとして保存

## 関連ファイル

- スクリプト: `scripts/feature_engineering/age_pclass_interaction_evaluation.py`
- 結果: `experiments/results/age_pclass_interaction_evaluation.txt`
- ログ: `experiments/logs/20251024_age_pclass_interaction_evaluation.md`（本ファイル）

---

**最終更新**: 2025-10-24
**作成者**: Claude Code
