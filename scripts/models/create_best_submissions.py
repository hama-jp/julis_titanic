"""
æœ‰æœ›ãªã‚µãƒ–ãƒŸãƒƒã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ

æå‡ºå›žæ•°5å›žã‚’å¤§åˆ‡ã«ä½¿ã†ãŸã‚ã€æœ€ã‚‚æœ‰æœ›ãªãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’åŽ³é¸ã—ã¦ä½œæˆï¼š
1. Hard Voting (LGB + GB + RF)
2. Soft Voting (ç¢ºçŽ‡å¹³å‡)
3. Weighted Soft Voting (CVã‚¹ã‚³ã‚¢æ¯”ä¾‹)
4. Best Single Model (RandomForest)

å„ãƒ¢ãƒ‡ãƒ«ã®OOFã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã—ã¦æŽ¨å¥¨é †ä½ã‚’æ±ºå®š
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import StratifiedKFold, cross_val_predict
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier
from sklearn.linear_model import LogisticRegression
import lightgbm as lgb
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder
import warnings
warnings.filterwarnings('ignore')

print('='*80)
print('æœ‰æœ›ãªã‚µãƒ–ãƒŸãƒƒã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ')
print('='*80)
print('æå‡ºå›žæ•°5å›žã‚’åŽ³é¸ã—ã¦ä½¿ç”¨')
print('='*80)

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
train = pd.read_csv('data/raw/train.csv')
test = pd.read_csv('data/raw/test.csv')

# ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
def engineer_features(df):
    """9ç‰¹å¾´é‡ï¼ˆLB 0.77751æ¤œè¨¼æ¸ˆã¿ï¼‰"""
    df = df.copy()

    df['Age_Missing'] = df['Age'].isnull().astype(int)
    df['Embarked_Missing'] = df['Embarked'].isnull().astype(int)

    df['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\.', expand=False)
    title_mapping = {
        'Mr': 'Mr', 'Miss': 'Miss', 'Mrs': 'Mrs', 'Master': 'Master',
        'Rev': 'Rare', 'Dr': 'Rare', 'Col': 'Rare', 'Major': 'Rare',
        'Mlle': 'Miss', 'Mme': 'Mrs', 'Don': 'Rare', 'Dona': 'Rare',
        'Lady': 'Rare', 'Countess': 'Rare', 'Jonkheer': 'Rare',
        'Sir': 'Rare', 'Capt': 'Rare', 'Ms': 'Miss'
    }
    df['Title'] = df['Title'].map(title_mapping)

    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1
    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)
    df['SmallFamily'] = ((df['FamilySize'] >= 2) & (df['FamilySize'] <= 4)).astype(int)

    df['Age'] = df.groupby(['Title', 'Pclass'])['Age'].transform(
        lambda x: x.fillna(x.median())
    )

    df['Fare'] = df.groupby('Pclass')['Fare'].transform(
        lambda x: x.fillna(x.median())
    )
    df['FareBin'] = pd.qcut(df['Fare'], q=4, labels=[0, 1, 2, 3], duplicates='drop')
    df['FareBin'] = df['FareBin'].astype(int)

    df['Embarked'] = df['Embarked'].fillna('S')

    return df

print('\nç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°...')
train_fe = engineer_features(train)
test_fe = engineer_features(test)

le_title = LabelEncoder()
train_fe['Title'] = le_title.fit_transform(train_fe['Title'])
test_fe['Title'] = le_title.transform(test_fe['Title'])

features = ['Pclass', 'Sex', 'Title', 'Age', 'IsAlone', 'FareBin',
            'SmallFamily', 'Age_Missing', 'Embarked_Missing']

train_fe['Sex'] = train_fe['Sex'].map({'male': 0, 'female': 1})
test_fe['Sex'] = test_fe['Sex'].map({'male': 0, 'female': 1})

X_train = train_fe[features]
y_train = train_fe['Survived']
X_test = test_fe[features]

print(f'Train: {len(X_train)} samples, Test: {len(X_test)} samples')
print(f'Features: {", ".join(features)}')

cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# ========================================================================
# ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«å®šç¾©
# ========================================================================
print('\n' + '='*80)
print('ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ï¼ˆæ—¢å­˜æœ€è‰¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰')
print('='*80)

lgb_model = lgb.LGBMClassifier(
    n_estimators=100, max_depth=2, num_leaves=4, min_child_samples=30,
    reg_alpha=1.0, reg_lambda=1.0, min_split_gain=0.01,
    learning_rate=0.05, subsample=0.8, colsample_bytree=0.8,
    random_state=42, verbose=-1
)

gb_model = GradientBoostingClassifier(
    n_estimators=100, max_depth=3, learning_rate=0.05,
    min_samples_split=20, min_samples_leaf=10, subsample=0.8,
    random_state=42
)

rf_model = RandomForestClassifier(
    n_estimators=100, max_depth=4, min_samples_split=20,
    min_samples_leaf=10, max_features='sqrt', random_state=42
)

print('âœ“ LightGBM (CV 0.8317è¨˜éŒ²)')
print('âœ“ GradientBoosting (CV 0.8316è¨˜éŒ²)')
print('âœ“ RandomForest (CV 0.8294è¨˜éŒ²)')

# ========================================================================
# ã‚µãƒ–ãƒŸãƒƒã‚·ãƒ§ãƒ³å€™è£œä½œæˆ
# ========================================================================
print('\n' + '='*80)
print('ã‚µãƒ–ãƒŸãƒƒã‚·ãƒ§ãƒ³å€™è£œã‚’ä½œæˆ')
print('='*80)

submissions = []

# ========================================================================
# 1. Best Single Model (RandomForest)
# ========================================================================
print('\nã€1. Best Single Model - RandomForestã€‘')
print('   ç†ç”±: å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã§æœ€é«˜CVã€ã‚·ãƒ³ãƒ—ãƒ«ã§å®‰å®š')

oof_rf = cross_val_predict(rf_model, X_train, y_train, cv=cv)
oof_score_rf = accuracy_score(y_train, oof_rf)

rf_model.fit(X_train, y_train)
pred_rf = rf_model.predict(X_test)

submissions.append({
    'name': 'Best_Single_RF',
    'filename': 'submission_best_single_rf.csv',
    'model': 'RandomForest',
    'oof_score': oof_score_rf,
    'predictions': pred_rf,
    'survival_rate': pred_rf.mean(),
    'description': 'å˜ä¸€ãƒ¢ãƒ‡ãƒ«æœ€è‰¯ã€ã‚·ãƒ³ãƒ—ãƒ«'
})

print(f'   OOF Score: {oof_score_rf:.4f}')
print(f'   Survival Rate: {pred_rf.mean():.3f}')

# ========================================================================
# 2. Hard Voting
# ========================================================================
print('\nã€2. Hard Voting (LGB + GB + RF)ã€‘')
print('   ç†ç”±: ç¾çŠ¶ã®å®Ÿç¸¾ãƒ¢ãƒ‡ãƒ«ã€å¤šæ•°æ±ºã§å®‰å®š')

voting_hard = VotingClassifier(
    estimators=[('lgb', lgb_model), ('gb', gb_model), ('rf', rf_model)],
    voting='hard'
)

oof_hard = cross_val_predict(voting_hard, X_train, y_train, cv=cv)
oof_score_hard = accuracy_score(y_train, oof_hard)

voting_hard.fit(X_train, y_train)
pred_hard = voting_hard.predict(X_test)

submissions.append({
    'name': 'Hard_Voting',
    'filename': 'submission_hard_voting.csv',
    'model': 'Hard Voting (LGB+GB+RF)',
    'oof_score': oof_score_hard,
    'predictions': pred_hard,
    'survival_rate': pred_hard.mean(),
    'description': 'å¤šæ•°æ±ºã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã€å®‰å®šæ€§é«˜'
})

print(f'   OOF Score: {oof_score_hard:.4f}')
print(f'   Survival Rate: {pred_hard.mean():.3f}')

# ========================================================================
# 3. Soft Voting
# ========================================================================
print('\nã€3. Soft Voting (LGB + GB + RF)ã€‘')
print('   ç†ç”±: ç¢ºçŽ‡å¹³å‡ã§Hard Votingã‚ˆã‚ŠæŸ”è»Ÿ')

voting_soft = VotingClassifier(
    estimators=[('lgb', lgb_model), ('gb', gb_model), ('rf', rf_model)],
    voting='soft'
)

oof_soft = cross_val_predict(voting_soft, X_train, y_train, cv=cv)
oof_score_soft = accuracy_score(y_train, oof_soft)

voting_soft.fit(X_train, y_train)
pred_soft = voting_soft.predict(X_test)

submissions.append({
    'name': 'Soft_Voting',
    'filename': 'submission_soft_voting.csv',
    'model': 'Soft Voting (LGB+GB+RF)',
    'oof_score': oof_score_soft,
    'predictions': pred_soft,
    'survival_rate': pred_soft.mean(),
    'description': 'ç¢ºçŽ‡å¹³å‡ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã€æŸ”è»Ÿæ€§é«˜'
})

print(f'   OOF Score: {oof_score_soft:.4f}')
print(f'   Survival Rate: {pred_soft.mean():.3f}')

# ========================================================================
# 4. Weighted Soft Voting (OOFã‚¹ã‚³ã‚¢æ¯”ä¾‹)
# ========================================================================
print('\nã€4. Weighted Soft Votingã€‘')
print('   ç†ç”±: å„ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã«å¿œã˜ãŸé‡ã¿ä»˜ã‘')

# å„ãƒ¢ãƒ‡ãƒ«ã®OOFã‚¹ã‚³ã‚¢å–å¾—
oof_lgb = cross_val_predict(lgb_model, X_train, y_train, cv=cv)
oof_gb = cross_val_predict(gb_model, X_train, y_train, cv=cv)
# oof_rf ã¯æ—¢ã«è¨ˆç®—æ¸ˆã¿

oof_score_lgb = accuracy_score(y_train, oof_lgb)
oof_score_gb = accuracy_score(y_train, oof_gb)
# oof_score_rf ã¯æ—¢ã«è¨ˆç®—æ¸ˆã¿

# é‡ã¿ã‚’æ­£è¦åŒ–
total_score = oof_score_lgb + oof_score_gb + oof_score_rf
weights = {
    'lgb': oof_score_lgb / total_score,
    'gb': oof_score_gb / total_score,
    'rf': oof_score_rf / total_score
}

print(f'   Weights: LGB={weights["lgb"]:.3f}, GB={weights["gb"]:.3f}, RF={weights["rf"]:.3f}')

# é‡ã¿ä»˜ãSoft Voting
voting_weighted = VotingClassifier(
    estimators=[('lgb', lgb_model), ('gb', gb_model), ('rf', rf_model)],
    voting='soft',
    weights=[weights['lgb'], weights['gb'], weights['rf']]
)

oof_weighted = cross_val_predict(voting_weighted, X_train, y_train, cv=cv)
oof_score_weighted = accuracy_score(y_train, oof_weighted)

voting_weighted.fit(X_train, y_train)
pred_weighted = voting_weighted.predict(X_test)

submissions.append({
    'name': 'Weighted_Soft_Voting',
    'filename': 'submission_weighted_soft_voting.csv',
    'model': 'Weighted Soft Voting',
    'oof_score': oof_score_weighted,
    'predictions': pred_weighted,
    'survival_rate': pred_weighted.mean(),
    'description': f'é‡ã¿ä»˜ãã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ« (LGB:{weights["lgb"]:.2f}, GB:{weights["gb"]:.2f}, RF:{weights["rf"]:.2f})'
})

print(f'   OOF Score: {oof_score_weighted:.4f}')
print(f'   Survival Rate: {pred_weighted.mean():.3f}')

# ========================================================================
# 5. LightGBMå˜ä½“ï¼ˆæœ€è‰¯å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«å€™è£œï¼‰
# ========================================================================
print('\nã€5. LightGBM Singleã€‘')
print('   ç†ç”±: è¨˜éŒ²ä¸Šæœ€é«˜å€‹åˆ¥CV 0.8317ã€Gapæœ€å° 0.0090')

oof_lgb_single = cross_val_predict(lgb_model, X_train, y_train, cv=cv)
oof_score_lgb_single = accuracy_score(y_train, oof_lgb_single)

lgb_model.fit(X_train, y_train)
pred_lgb = lgb_model.predict(X_test)

submissions.append({
    'name': 'LightGBM_Single',
    'filename': 'submission_lightgbm_single.csv',
    'model': 'LightGBM',
    'oof_score': oof_score_lgb_single,
    'predictions': pred_lgb,
    'survival_rate': pred_lgb.mean(),
    'description': 'æœ€è‰¯å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«ã€éŽå­¦ç¿’æœ€å°'
})

print(f'   OOF Score: {oof_score_lgb_single:.4f}')
print(f'   Survival Rate: {pred_lgb.mean():.3f}')

# ========================================================================
# çµæžœã‚µãƒžãƒªãƒ¼ã¨æŽ¨å¥¨é †ä½
# ========================================================================
print('\n' + '='*80)
print('ã‚µãƒ–ãƒŸãƒƒã‚·ãƒ§ãƒ³å€™è£œã‚µãƒžãƒªãƒ¼')
print('='*80)

# DataFrameã«æ•´ç†
df_submissions = pd.DataFrame(submissions)
df_submissions = df_submissions.sort_values('oof_score', ascending=False).reset_index(drop=True)

print('\nã€OOFã‚¹ã‚³ã‚¢é †ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã€‘')
for idx, row in df_submissions.iterrows():
    print(f"\n{idx+1}ä½: {row['name']}")
    print(f"     OOF Score: {row['oof_score']:.4f}")
    print(f"     Model: {row['model']}")
    print(f"     Survival Rate: {row['survival_rate']:.3f}")
    print(f"     èª¬æ˜Ž: {row['description']}")

# ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ
print('\n' + '='*80)
print('ã‚µãƒ–ãƒŸãƒƒã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ')
print('='*80)

for idx, row in df_submissions.iterrows():
    submission = pd.DataFrame({
        'PassengerId': test['PassengerId'],
        'Survived': row['predictions']
    })
    submission.to_csv(row['filename'], index=False)
    print(f"âœ… {row['filename']}")

# æŽ¨å¥¨é †ä½ã‚’ä¿å­˜
recommendation = df_submissions[['name', 'filename', 'model', 'oof_score', 'survival_rate', 'description']].copy()
recommendation.to_csv('submission_recommendations.csv', index=False)
print(f"\nâœ… submission_recommendations.csv (æŽ¨å¥¨é †ä½)")

# ========================================================================
# æå‡ºæŽ¨å¥¨
# ========================================================================
print('\n' + '='*80)
print('ðŸ“Š æå‡ºæŽ¨å¥¨ï¼ˆ5å›žã‚’åŽ³é¸ï¼‰')
print('='*80)

print('\nã€æŽ¨å¥¨æå‡ºé †åºã€‘\n')

best = df_submissions.iloc[0]
second = df_submissions.iloc[1]
third = df_submissions.iloc[2]

print(f"ðŸ¥‡ 1stæå‡º: {best['filename']}")
print(f"   ãƒ¢ãƒ‡ãƒ«: {best['model']}")
print(f"   OOF: {best['oof_score']:.4f} (æœ€é«˜ã‚¹ã‚³ã‚¢)")
print(f"   ç†ç”±: OOFæœ€é«˜ã€æœ€ã‚‚æœ‰æœ›")

print(f"\nðŸ¥ˆ 2ndæå‡º: {second['filename']}")
print(f"   ãƒ¢ãƒ‡ãƒ«: {second['model']}")
print(f"   OOF: {second['oof_score']:.4f}")
print(f"   ç†ç”±: OOF 2ä½ã€{best['name']}ã¨æ¯”è¼ƒæ¤œè¨¼")

print(f"\nðŸ¥‰ 3rdæå‡º: {third['filename']}")
print(f"   ãƒ¢ãƒ‡ãƒ«: {third['model']}")
print(f"   OOF: {third['oof_score']:.4f}")
print(f"   ç†ç”±: OOF 3ä½ã€å¤šæ§˜æ€§ç¢ºä¿")

# äºˆæ¸¬ã®ä¸€è‡´çŽ‡ã‚’ç¢ºèª
print('\n' + '='*80)
print('äºˆæ¸¬ã®ä¸€è‡´çŽ‡ï¼ˆå¤šæ§˜æ€§ç¢ºèªï¼‰')
print('='*80)

for i in range(len(df_submissions)):
    for j in range(i+1, len(df_submissions)):
        name1 = df_submissions.iloc[i]['name']
        name2 = df_submissions.iloc[j]['name']
        pred1 = df_submissions.iloc[i]['predictions']
        pred2 = df_submissions.iloc[j]['predictions']

        agreement = (pred1 == pred2).mean()
        print(f"{name1} vs {name2}: {agreement:.1%} ä¸€è‡´")

print('\n' + '='*80)
print('ã‚µãƒ–ãƒŸãƒƒã‚·ãƒ§ãƒ³ä½œæˆå®Œäº†ï¼')
print('='*80)
print('\nâœ… 5ã¤ã®å€™è£œãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã—ãŸ')
print('âœ… OOFã‚¹ã‚³ã‚¢é †ã«æŽ¨å¥¨é †ä½ã‚’æ±ºå®šã—ã¾ã—ãŸ')
print('âœ… submission_recommendations.csv ã§è©³ç´°ç¢ºèªã§ãã¾ã™')
print('\næ…Žé‡ã«æå‡ºã—ã¦ãã ã•ã„ï¼æ®‹ã‚Š5å›žã§ã™ã€‚')
