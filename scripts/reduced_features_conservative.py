"""
Reduced Features with Conservative Parameters

Based on multicollinearity analysis:
- Remove Pclass_Sex (VIF = âˆž, redundant with Pclass + Sex)
- Use 7 features: Pclass, Sex, Title, Age, IsAlone, FareBin, SmallFamily
- Conservative parameters to reduce overfitting
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import StratifiedKFold, cross_val_score
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score
import warnings
warnings.filterwarnings('ignore')

print('='*80)
print('REDUCED FEATURES WITH CONSERVATIVE PARAMETERS')
print('='*80)
print('Strategy: Remove Pclass_Sex to reduce multicollinearity')
print('Features: 7 (removed Pclass_Sex from original 8)')
print('Parameters: Conservative to prevent overfitting')
print('='*80)

# Load data
train = pd.read_csv('data/raw/train.csv')
test = pd.read_csv('data/raw/test.csv')

# Feature engineering
def engineer_features(df):
    df = df.copy()

    # Title extraction
    df['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\.', expand=False)
    title_mapping = {
        'Mr': 'Mr', 'Miss': 'Miss', 'Mrs': 'Mrs', 'Master': 'Master',
        'Rev': 'Rare', 'Dr': 'Rare', 'Col': 'Rare', 'Major': 'Rare',
        'Mlle': 'Miss', 'Mme': 'Mrs', 'Don': 'Rare', 'Dona': 'Rare',
        'Lady': 'Rare', 'Countess': 'Rare', 'Jonkheer': 'Rare',
        'Sir': 'Rare', 'Capt': 'Rare', 'Ms': 'Miss'
    }
    df['Title'] = df['Title'].map(title_mapping)

    # Family features
    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1
    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)
    df['SmallFamily'] = ((df['FamilySize'] >= 2) & (df['FamilySize'] <= 4)).astype(int)

    # Age imputation
    df['Age'] = df.groupby(['Title', 'Pclass'])['Age'].transform(
        lambda x: x.fillna(x.median())
    )

    # Fare imputation and binning
    df['Fare'] = df.groupby('Pclass')['Fare'].transform(
        lambda x: x.fillna(x.median())
    )
    df['FareBin'] = pd.qcut(df['Fare'], q=4, labels=[0, 1, 2, 3], duplicates='drop')
    df['FareBin'] = df['FareBin'].astype(int)

    return df

print('\nEngineering features...')
train_fe = engineer_features(train)
test_fe = engineer_features(test)

# Encoding
le_sex = LabelEncoder()
train_fe['Sex'] = le_sex.fit_transform(train_fe['Sex'])
test_fe['Sex'] = le_sex.transform(test_fe['Sex'])

le_title = LabelEncoder()
train_fe['Title'] = le_title.fit_transform(train_fe['Title'])
test_fe['Title'] = le_title.transform(test_fe['Title'])

# REDUCED FEATURES (removed Pclass_Sex)
features = ['Pclass', 'Sex', 'Title', 'Age', 'IsAlone', 'FareBin', 'SmallFamily']

X_train = train_fe[features]
y_train = train_fe['Survived']
X_test = test_fe[features]

print(f'\nTraining data: {len(X_train)} samples')
print(f'Features ({len(features)}): {", ".join(features)}')
print(f'Test data: {len(X_test)} samples')

# Cross-validation
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# ============================================================================
# CONSERVATIVE MODEL CONFIGURATIONS
# ============================================================================
print('\n' + '='*80)
print('TESTING CONSERVATIVE CONFIGURATIONS')
print('='*80)

model_configs = [
    {
        'name': 'RF_Conservative',
        'model': RandomForestClassifier(
            n_estimators=100,
            max_depth=4,
            min_samples_split=20,
            min_samples_leaf=10,
            max_features='sqrt',
            random_state=42
        ),
        'description': 'Random Forest: shallow depth, high min_samples'
    },
    {
        'name': 'GB_Conservative',
        'model': GradientBoostingClassifier(
            n_estimators=100,
            max_depth=3,
            learning_rate=0.05,
            min_samples_split=20,
            min_samples_leaf=10,
            subsample=0.8,
            random_state=42
        ),
        'description': 'Gradient Boosting: shallow depth, low learning rate'
    },
    {
        'name': 'LR_Conservative',
        'model': LogisticRegression(
            C=0.5,
            penalty='l2',
            max_iter=1000,
            random_state=42
        ),
        'description': 'Logistic Regression: strong regularization'
    },
]

results = []

for config in model_configs:
    print(f'\n{config["name"]}:')
    print(f'  {config["description"]}')

    model = config['model']

    # Cross-validation
    cv_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='accuracy')
    cv_mean = cv_scores.mean()
    cv_std = cv_scores.std()

    # Train on all data
    model.fit(X_train, y_train)
    train_pred = model.predict(X_train)
    train_acc = accuracy_score(y_train, train_pred)

    # Predict on test
    test_pred = model.predict(X_test)
    survival_rate = test_pred.mean()

    # Calculate overfitting metric
    overfit_gap = train_acc - cv_mean

    results.append({
        'name': config['name'],
        'cv_mean': cv_mean,
        'cv_std': cv_std,
        'train_acc': train_acc,
        'overfit_gap': overfit_gap,
        'survival_rate': survival_rate,
        'predictions': test_pred
    })

    print(f'  CV Score: {cv_mean:.4f} (Â±{cv_std:.4f})')
    print(f'  Training Accuracy: {train_acc:.4f}')
    print(f'  Overfitting Gap: {overfit_gap:.4f}')
    print(f'  Survival Rate: {survival_rate:.3f}')

# ============================================================================
# MODEL COMPARISON
# ============================================================================
print('\n' + '='*80)
print('MODEL COMPARISON')
print('='*80)

results_df = pd.DataFrame(results)
results_df = results_df.sort_values('cv_mean', ascending=False)

print('\nRanked by CV Score:')
print(results_df[['name', 'cv_mean', 'cv_std', 'train_acc', 'overfit_gap']].to_string(index=False))

# Select best model (highest CV, lowest overfitting)
# Prioritize models with small overfitting gap
results_df['score'] = results_df['cv_mean'] - (results_df['overfit_gap'] * 0.5)
best_idx = results_df['score'].idxmax()
best_model = results_df.loc[best_idx]

print('\n' + '='*80)
print('BEST MODEL SELECTION')
print('='*80)
print(f'\nBest Model: {best_model["name"]}')
print(f'  CV Score: {best_model["cv_mean"]:.4f} (Â±{best_model["cv_std"]:.4f})')
print(f'  Training Accuracy: {best_model["train_acc"]:.4f}')
print(f'  Overfitting Gap: {best_model["overfit_gap"]:.4f}')
print(f'  Survival Rate: {best_model["survival_rate"]:.3f}')

# ============================================================================
# CREATE SUBMISSIONS
# ============================================================================
print('\n' + '='*80)
print('CREATING SUBMISSION FILES')
print('='*80)

# Create submission for each model
for result in results:
    model_name = result['name']
    predictions = result['predictions']

    submission = pd.DataFrame({
        'PassengerId': test['PassengerId'],
        'Survived': predictions
    })

    filename = f'submission_{model_name.lower()}_7features.csv'
    submission.to_csv(filename, index=False)

    print(f'\n{filename}')
    print(f'  Model: {model_name}')
    print(f'  CV Score: {result["cv_mean"]:.4f}')
    print(f'  Overfitting Gap: {result["overfit_gap"]:.4f}')

# ============================================================================
# FINAL RECOMMENDATION
# ============================================================================
print('\n' + '='*80)
print('FINAL RECOMMENDATION')
print('='*80)

print(f"""
ðŸŽ¯ RECOMMENDED SUBMISSION: submission_{best_model['name'].lower()}_7features.csv

Strategy Changes:
1. âœ… Removed Pclass_Sex (reduced multicollinearity)
2. âœ… Using 7 features instead of 8
3. âœ… Conservative parameters (shallow trees, strong regularization)
4. âœ… Minimized overfitting gap

Model Details:
- Features: {", ".join(features)}
- CV Score: {best_model['cv_mean']:.4f} (Â±{best_model['cv_std']:.4f})
- Training Accuracy: {best_model['train_acc']:.4f}
- Overfitting Gap: {best_model['overfit_gap']:.4f}

Expected Improvement:
- Previous best LB: 0.78229 (multi-model ensemble with 8 features)
- Previous issue: High overfitting (CV 0.8283, LB 0.78229, gap 0.046)
- New approach: Lower overfitting gap ({best_model['overfit_gap']:.4f})
- Expected LB: ~0.80-0.82

Why This Should Work Better:
1. Removed redundant feature causing multicollinearity
2. Conservative parameters reduce overfitting
3. Lower gap between training and CV scores
4. More likely to generalize to test data

Submit all 3 models to compare:
1. submission_rf_conservative_7features.csv
2. submission_gb_conservative_7features.csv
3. submission_lr_conservative_7features.csv

Recommended order: GB â†’ RF â†’ LR
""")

print('\n' + '='*80)
print('DONE! Ready for submission.')
print('='*80)
